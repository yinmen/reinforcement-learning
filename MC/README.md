## Model-Free Prediction & Control with Monte Carlo (MC)


### Learning Goals

- Understand the difference between Prediction and Control
- Know how to use the MC method for predicting state values and state-action values
- Understand the on-policy first-visit MC control algorithm
- Understand the off-policy every-visit MC control algorithm
- Understand the benefits of MC algorithms over the DP approach


### Lectures & Readings

**Required:**

- [Reinforcement Learning: An Introduction](https://www.dropbox.com/s/b3psxv2r0ccmf80/book2015oct.pdf) - Chapter 5: Monte Carlo Methods


**Optional:**

- David Silver's RL Course Lecture 4 - Model-Free Prediction ([video](https://www.youtube.com/watch?v=PnHCvfgC_ZA), [slides](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/MC-TD.pdf))
- David Silver's RL Course Lecture 5 - Model-Free Control ([video](https://www.youtube.com/watch?v=0g4j2k_Ggc4), [slides](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/control.pdf))


### Exercises

- Implement the MC method to estimate state values in Python
- Implement the MC method to estimate state-action values in Python
- Implement the on-policy first-visit MC control algorithm in Python
- Implement the off-policy every-visit MC control algorithm in Python